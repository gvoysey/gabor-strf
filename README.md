## Modeling of Spectro-Temporal Receptive Fields and Simulation of the Population Response in Zebra Finch Field-L

The zebra finch is a good model species for the study of complex sound learning and perception. Zebra finch song is spectrotemporally complex, feature-rich, and has similar acoustic properties to human speech. Field L, the avian analogue of auditory cortex, is the area of the brain in which songs are analyzed and processed. Previous studies have quantified the responses of single auditory neurons to sound using Spectro-Temporal Receptive Fields (STRFs). Though a collection of these STRFs exist, they have not been systematically modeled and characterized to show the variety of feature encoding that Field L possesses. Knowledge of the diversity of Field L could impact studies into neural coding, speech learning, and speech percep- tion. Therefore, this project created models of STRFs, validated these models, used these models to generate firing-rate responses to songs, and characterized these responses visually into the so-called population response.

Modeling was accomplished by a least-squares curve fitting of experimentally characterized STRFs to Gabor Functions. These have been previously shown to model neural data well. Firing rate generation was accomplished by the convolution of model responses to a series of birdsongs. [EarLab](https://github.com/AuditoryBiophysicsLab/EarLab), a software suite specializing in modeling and visualization of the auditory system, was used to visualize the population response.

The visualizations of the population response revealed the representation of spectrotemporally complex sound by neural population in Field L.
